# Pinecone Document Upsert Tool

This tool provides a comprehensive solution for upserting text documents to a Pinecone vector database using embeddings generated by Ollama models.

## Features

- **Document Upserting**: Upsert individual text documents or batches of documents
- **Directory Processing**: Process all `.txt` files from a directory
- **Vector Search**: Query the index for similar documents
- **Index Management**: Initialize, list, and manage Pinecone indexes
- **Batch Processing**: Efficient batch processing with configurable batch sizes
- **Metadata Support**: Add custom metadata to your documents
- **CLI Interface**: Command-line interface for easy integration

## Prerequisites

1. **Pinecone Account**: Sign up at [pinecone.io](https://pinecone.io)
2. **Ollama**: Install and run Ollama locally
3. **Environment Variables**: Set up your Pinecone credentials

## Setup

### 1. Install Dependencies

```bash
npm install @pinecone-database/pinecone
```

### 2. Environment Variables

Create a `.env` file in your project root:

```env
PINECONE_API_KEY=your_pinecone_api_key_here
PINECONE_ENVIRONMENT=your_pinecone_environment_here
OLLAMA_API_URL=http://127.0.0.1:11434
```

### 3. Pull Embedding Model

```bash
ollama pull nomic-embed-text:v1.5
```

## Usage

### Programmatic Usage

#### Basic Setup

```typescript
import { PineconeManager, PineconeConfig } from './src/embeddings-tools/pinecone-manager';

const config: PineconeConfig = {
  apiKey: process.env.PINECONE_API_KEY!,
  environment: process.env.PINECONE_ENVIRONMENT!,
  indexName: 'my-docs'
};

const pineconeManager = new PineconeManager(config);
```

#### Initialize Index

```typescript
// Initialize a new index with 768-dimensional vectors
await pineconeManager.initializeIndex(768);
```

#### Upsert Single Document

```typescript
await pineconeManager.upsertDocument(
  'This is the content of my document.',
  'doc-001',
  {
    metadata: {
      category: 'technology',
      author: 'John Doe',
      timestamp: new Date().toISOString()
    },
    embeddingModel: 'nomic-embed-text:v1.5'
  }
);
```

#### Upsert Multiple Documents

```typescript
const documents = [
  {
    text: 'First document content',
    id: 'doc-001',
    metadata: { category: 'tech' }
  },
  {
    text: 'Second document content',
    id: 'doc-002',
    metadata: { category: 'science' }
  }
];

await pineconeManager.upsertDocuments(documents, {
  batchSize: 100,
  embeddingModel: 'nomic-embed-text:v1.5'
});
```

#### Upsert from Directory

```typescript
// Upsert all .txt files from a directory
await pineconeManager.upsertFromDirectory('./documents', {
  batchSize: 50,
  embeddingModel: 'nomic-embed-text:v1.5'
});
```

#### Query the Index

```typescript
const results = await pineconeManager.query(
  'What is machine learning?',
  10, // topK
  undefined, // namespace (optional)
  { category: 'tech' } // filter (optional)
);

console.log('Query results:', results);
```

#### Get Index Statistics

```typescript
const stats = await pineconeManager.getIndexStats();
console.log('Index statistics:', stats);
```

#### Delete Vectors

```typescript
await pineconeManager.deleteVectors(['doc-001', 'doc-002']);
```

### CLI Usage

The tool provides a comprehensive CLI interface for all operations.
### If installed globally:
```
Initialize index
pinecone-cli init --index-name my-docs --dimension 768

Upsert documents from directory
pinecone-cli upsert-directory --index-name my-docs --directory ./documents

Query the index
pinecone-cli query --index-name my-docs --query "machine learning" --top-k 5
```

#### Initialize Index

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts init --index-name my-docs --dimension 768
```

#### Upsert Single File

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts upsert-file \
  --index-name my-docs \
  --file ./document.txt \
  --id doc-001
```

#### Upsert Directory

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts upsert-directory \
  --index-name my-docs \
  --directory ./documents \
  --batch-size 50
```

#### Upsert Text

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts upsert-text \
  --index-name my-docs \
  --text "This is my document content" \
  --id doc-002
```

#### Query Index

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts query \
  --index-name my-docs \
  --query "machine learning" \
  --top-k 5
```

#### Get Statistics

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts stats --index-name my-docs
```

#### List Indexes

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts list-indexes
```

#### Delete Vectors

```bash
npx ts-node src/embeddings-tools/pinecone-cli.ts delete \
  --index-name my-docs \
  --id doc-001
```

## Configuration Options

### PineconeConfig

```typescript
interface PineconeConfig {
  apiKey: string;        // Your Pinecone API key
  environment: string;   // Your Pinecone environment
  indexName: string;     // Name of the index to use
}
```

### UpsertOptions

```typescript
interface UpsertOptions {
  batchSize?: number;           // Batch size for processing (default: 100)
  namespace?: string;           // Pinecone namespace
  metadata?: DocumentMetadata;  // Additional metadata
  embeddingModel?: string;      // Embedding model name (default: nomic-embed-text:v1.5)
}
```

### DocumentMetadata

```typescript
interface DocumentMetadata {
  filename?: string;     // Original filename
  content?: string;      // Document content
  chunkIndex?: number;   // Chunk index if document is chunked
  totalChunks?: number;  // Total number of chunks
  timestamp?: string;    // Processing timestamp
  [key: string]: any;    // Additional custom metadata
}
```

## Examples

### Complete Example

See `src/embeddings-tools/examples/pinecone-example.ts` for a complete working example that demonstrates:

- Index initialization
- Document upserting (individual and batch)
- Directory processing
- Querying
- Statistics retrieval

Run the example:

```bash
npx ts-node src/embeddings-tools/examples/pinecone-example.ts
```

### Real-world Usage

```typescript
import { PineconeManager } from './src/embeddings-tools/pinecone-manager';
import * as fs from 'fs';
import * as path from 'path';

async function processDocuments() {
  const pineconeManager = new PineconeManager({
    apiKey: process.env.PINECONE_API_KEY!,
    environment: process.env.PINECONE_ENVIRONMENT!,
    indexName: 'knowledge-base'
  });

  // Initialize index
  await pineconeManager.initializeIndex(768);

  // Process documents from a directory
  const documentsDir = './knowledge-base';
  const files = fs.readdirSync(documentsDir)
    .filter(file => file.endsWith('.txt'))
    .map(file => path.join(documentsDir, file));

  // Create documents array
  const documents = files.map(filePath => {
    const content = fs.readFileSync(filePath, 'utf-8');
    const filename = path.basename(filePath, '.txt');
    return {
      text: content,
      id: filename,
      metadata: {
        filename: path.basename(filePath),
        filepath: filePath,
        category: 'knowledge-base',
        timestamp: new Date().toISOString()
      }
    };
  });

  // Upsert documents
  await pineconeManager.upsertDocuments(documents, {
    batchSize: 50,
    embeddingModel: 'nomic-embed-text:v1.5'
  });

  console.log(`Successfully upserted ${documents.length} documents`);
}

processDocuments().catch(console.error);
```

## Error Handling

The tool includes comprehensive error handling for common scenarios:

- **Invalid API Key**: Check your Pinecone API key
- **Invalid Environment**: Verify your Pinecone environment
- **Index Not Found**: Ensure the index exists or initialize it first
- **Ollama Connection**: Make sure Ollama is running and accessible
- **Model Not Found**: Pull the required embedding model

## Best Practices

1. **Batch Processing**: Use appropriate batch sizes (50-100) for large datasets
2. **Metadata**: Include relevant metadata for better filtering and organization
3. **Index Naming**: Use descriptive index names for better organization
4. **Error Handling**: Always wrap operations in try-catch blocks
5. **Environment Variables**: Use environment variables for sensitive data
6. **Model Selection**: Choose appropriate embedding models for your use case

## Troubleshooting

### Common Issues

1. **"Index not found" error**
   - Initialize the index first using `initializeIndex()`
   - Check that the index name is correct

2. **"Invalid API key" error**
   - Verify your Pinecone API key in environment variables
   - Check that the key has the correct permissions

3. **"Model not found" error**
   - Pull the required model: `ollama pull nomic-embed-text:v1.5`
   - Check that Ollama is running

4. **"Connection refused" error**
   - Ensure Ollama is running on the correct port
   - Check the `OLLAMA_API_URL` environment variable

### Debug Mode

Enable debug logging by setting the environment variable:

```bash
DEBUG=pinecone-manager npx ts-node your-script.ts
```

## API Reference

### PineconeManager Class

#### Constructor
```typescript
new PineconeManager(config: PineconeConfig)
```

#### Methods

- `initializeIndex(dimension?: number): Promise<void>`
- `upsertDocument(text: string, id: string, options?: UpsertOptions): Promise<void>`
- `upsertDocuments(documents: Array<{text: string, id: string, metadata?: DocumentMetadata}>, options?: UpsertOptions): Promise<void>`
- `upsertFromDirectory(directoryPath: string, options?: UpsertOptions): Promise<void>`
- `query(queryText: string, topK?: number, namespace?: string, filter?: any): Promise<any>`
- `deleteVectors(ids: string[], namespace?: string): Promise<void>`
- `getIndexStats(): Promise<any>`
- `listIndexes(): Promise<any[]>`

## License

This tool is part of the ollama-openai-client project and follows the same license terms. 